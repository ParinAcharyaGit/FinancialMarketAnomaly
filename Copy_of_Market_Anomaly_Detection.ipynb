{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. Load the data and pre-process\n",
        "try:\n",
        "    df = pd.read_excel('Financial_Market_Data.xlsx')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'Financial_Market_Data.xlsx' not found. Please ensure the file exists and the path is correct.\")\n",
        "    exit()\n",
        "\n",
        "# Separate the \"Data\" column header if it exists\n",
        "if 'Data' in df.columns:\n",
        "    df = df.drop('Data', axis=1)\n",
        "\n",
        "# 2. Handle Missing Values (if any):\n",
        "for col in df.columns:\n",
        "  if df[col].isnull().any():\n",
        "    if pd.api.types.is_numeric_dtype(df[col]):\n",
        "      df[col] = df[col].fillna(df[col].mean())\n",
        "    else:\n",
        "      df[col] = df[col].fillna(df[col].mode()[0])\n",
        "\n",
        "if 'Data' in df.columns:\n",
        "    df = df.sort_values(by=\"Data\") # Sort by Date\n",
        "\n",
        "# 3. Split data into training and testing sets based on date\n",
        "    train_size = int(len(df) * 0.8)\n",
        "    X = df.drop(\"Y\", axis=1)\n",
        "    y = df[\"Y\"]\n",
        "    X_train, X_test = X[:train_size], X[train_size:]\n",
        "    y_train, y_test = y[:train_size], y[train_size:]\n",
        "else:\n",
        "    print(\"Warning: No 'Data' column found. Performing a random split. This might introduce data leakage if the data has a temporal component.\")\n",
        "    X = df.drop(\"Y\", axis=1)\n",
        "    y = df[\"Y\"]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. Scale data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 5. RandomForestClassifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# 6. Evaluation\n",
        "y_pred = rf_model.predict(X_test)\n",
        "print(\"Random Forest Classifier:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "\n",
        "# 7. Feature Importance\n",
        "feature_importances = rf_model.feature_importances_\n",
        "print(\"\\nFeature Importances:\")\n",
        "for i, col in enumerate(X.columns):\n",
        "    print(f\"{col}: {feature_importances[i]}\")\n",
        "\n",
        "# VIX index Analysis\n",
        "print(df[df['Y']==1]['VIX'].describe())\n",
        "print(df[df['Y']==0]['VIX'].describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiIb3Q7KDR5D",
        "outputId": "f0b6ac15-d01e-4aaf-ade9-d097d8df9d30"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No 'Data' column found. Performing a random split. This might introduce data leakage if the data has a temporal component.\n",
            "Random Forest Classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.96      0.94       177\n",
            "           1       0.82      0.72      0.77        46\n",
            "\n",
            "    accuracy                           0.91       223\n",
            "   macro avg       0.88      0.84      0.86       223\n",
            "weighted avg       0.91      0.91      0.91       223\n",
            "\n",
            "Accuracy: 0.9103139013452914\n",
            "\n",
            "Feature Importances:\n",
            "XAU BGNL: 0.019938961728417786\n",
            "ECSURPUS: 0.014308479440818067\n",
            "BDIY: 0.018979551723660882\n",
            "CRY: 0.027333723729892415\n",
            "DXY: 0.014923530639707578\n",
            "JPY: 0.02523483670118365\n",
            "GBP: 0.014637912188822261\n",
            "Cl1: 0.027539226100066136\n",
            "VIX: 0.17848619604113655\n",
            "USGG30YR: 0.020956570237132086\n",
            "GT10: 0.01901164907333174\n",
            "USGG2YR: 0.016910995830013743\n",
            "USGG3M: 0.010389305055473908\n",
            "US0001M: 0.017364144253895906\n",
            "GTDEM30Y: 0.010336129264500747\n",
            "GTDEM10Y: 0.014955640394162004\n",
            "GTDEM2Y: 0.012249363765749534\n",
            "EONIA: 0.01689701666608823\n",
            "GTITL30YR: 0.051734965262994856\n",
            "GTITL10YR: 0.053943886167432904\n",
            "GTITL2YR: 0.036938358675684874\n",
            "GTJPY30YR: 0.01610605439035741\n",
            "GTJPY10YR: 0.0133645590194027\n",
            "GTJPY2YR: 0.0162453747733938\n",
            "GTGBP30Y: 0.014382612619570984\n",
            "GTGBP20Y: 0.012139497578111136\n",
            "GTGBP2Y: 0.013558312986836869\n",
            "LUMSTRUU: 0.017173825963334163\n",
            "LMBITR: 0.015043702113391802\n",
            "LUACTRUU: 0.011648421448177954\n",
            "LF98TRUU: 0.018226360825306865\n",
            "LG30TRUU: 0.019242892742561597\n",
            "LP01TREU: 0.01758342748671051\n",
            "EMUSTRUU: 0.01221120388289009\n",
            "LF94TRUU: 0.018356012982267786\n",
            "MXUS: 0.03324661766624066\n",
            "MXEU: 0.022923591382667478\n",
            "MXJP: 0.03734990779882599\n",
            "MXBR: 0.017283518122001316\n",
            "MXRU: 0.022272473232807982\n",
            "MXIN: 0.016130737459210127\n",
            "MXCN: 0.012440452585766835\n",
            "count    237.000000\n",
            "mean      29.919283\n",
            "std       11.210110\n",
            "min       13.710000\n",
            "25%       21.910000\n",
            "50%       27.050000\n",
            "75%       35.080000\n",
            "max       75.910000\n",
            "Name: VIX, dtype: float64\n",
            "count    874.000000\n",
            "mean      17.300263\n",
            "std        5.194502\n",
            "min        9.430000\n",
            "25%       13.120000\n",
            "50%       16.010000\n",
            "75%       20.747500\n",
            "max       32.880000\n",
            "Name: VIX, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rf_model.predict(X_test)\n",
        "print(\"Random Forest Classifier:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")"
      ],
      "metadata": {
        "id": "ltMkIxLsF2Q3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18bc9b29-5a30-41f9-bcc8-cd7b83c8f7eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.96      0.94       177\n",
            "           1       0.82      0.72      0.77        46\n",
            "\n",
            "    accuracy                           0.91       223\n",
            "   macro avg       0.88      0.84      0.86       223\n",
            "weighted avg       0.91      0.91      0.91       223\n",
            "\n",
            "Accuracy: 0.9103139013452914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the dataframe to perform moving averages of 30 days\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "numerical_features = X.select_dtypes(include=['number']).columns  # Get numerical features\n",
        "\n",
        "for col in numerical_features:\n",
        "    df[f'{col}_MA30'] = df[col].rolling(window=30).mean()\n",
        "\n",
        "# Handle NaN values created by the moving average calculation\n",
        "df.fillna(method='bfill', inplace=True) # Backfill for initial rows with no MA30 values\n",
        "\n",
        "# Split data into training and testing sets AGAIN after feature engineering\n",
        "if 'Data' in df.columns:\n",
        "    df = df.sort_values(by=\"Data\")\n",
        "    train_size = int(len(df) * 0.8)\n",
        "    X = df.drop(\"Y\", axis=1)\n",
        "    y = df[\"Y\"]\n",
        "    X_train, X_test = X[:train_size], X[train_size:]\n",
        "    y_train, y_test = y[:train_size], y[train_size:]\n",
        "else:\n",
        "    X = df.drop(\"Y\", axis=1)\n",
        "    y = df[\"Y\"]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# Re-train the model\n",
        "rf_model_ma = RandomForestClassifier(random_state=42)\n",
        "rf_model_ma.fit(X_train, y_train)\n",
        "\n",
        "# Evaluation\n",
        "y_pred_ma = rf_model_ma.predict(X_test)\n",
        "print(\"\\nRandom Forest Classifier (with 30-day Moving Averages):\")\n",
        "print(classification_report(y_test, y_pred_ma))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_ma)}\")\n",
        "\n",
        "# Display the updated DataFrame (first few rows)\n",
        "print(\"\\nUpdated DataFrame with Moving Averages:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "x7QnHwCtiDKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72d3be6e-6606-4f8c-a966-8935eda3a047"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-3244026dcdde>:15: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df.fillna(method='bfill', inplace=True) # Backfill for initial rows with no MA30 values\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest Classifier (with 30-day Moving Averages):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95       177\n",
            "           1       0.85      0.74      0.79        46\n",
            "\n",
            "    accuracy                           0.92       223\n",
            "   macro avg       0.89      0.85      0.87       223\n",
            "weighted avg       0.92      0.92      0.92       223\n",
            "\n",
            "Accuracy: 0.9192825112107623\n",
            "\n",
            "Updated DataFrame with Moving Averages:\n",
            "   Y  XAU BGNL  ECSURPUS  BDIY     CRY     DXY     JPY     GBP    Cl1    VIX  \\\n",
            "0  0    283.25     0.077  1388  157.26  100.56  105.86  1.6460  25.77  22.50   \n",
            "1  0    287.65     0.043  1405  165.01  101.86  105.47  1.6383  28.85  21.50   \n",
            "2  0    287.15     0.135  1368  167.24  102.41  106.04  1.6496  28.28  23.02   \n",
            "3  0    282.75     0.191  1311  166.85  104.92  107.85  1.6106  28.22  23.45   \n",
            "4  1    298.40     0.312  1277  165.43  104.22  109.30  1.6108  28.02  21.25   \n",
            "\n",
            "   ...  LP01TREU_MA30  EMUSTRUU_MA30  LF94TRUU_MA30  MXUS_MA30   MXEU_MA30  \\\n",
            "0  ...     118.584197     244.733847     123.354023   1403.228  136.055667   \n",
            "1  ...     118.584197     244.733847     123.354023   1403.228  136.055667   \n",
            "2  ...     118.584197     244.733847     123.354023   1403.228  136.055667   \n",
            "3  ...     118.584197     244.733847     123.354023   1403.228  136.055667   \n",
            "4  ...     118.584197     244.733847     123.354023   1403.228  136.055667   \n",
            "\n",
            "    MXJP_MA30   MXBR_MA30   MXRU_MA30   MXIN_MA30  MXCN_MA30  \n",
            "0  988.001333  851.738667  233.233333  224.685333  30.472667  \n",
            "1  988.001333  851.738667  233.233333  224.685333  30.472667  \n",
            "2  988.001333  851.738667  233.233333  224.685333  30.472667  \n",
            "3  988.001333  851.738667  233.233333  224.685333  30.472667  \n",
            "4  988.001333  851.738667  233.233333  224.685333  30.472667  \n",
            "\n",
            "[5 rows x 85 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "import os\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "client = OpenAI()\n",
        "predictions = y_pred_ma\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Based on the following model predictions for financial market anomalies from the dataset {df}, propose a data-driven investment strategy focusing on minimizing losses and maximizing returns.  The predictions (1 indicates an anomaly, 0 indicates no anomaly).  Consider the following in your analysis and recommendations:\n",
        "\n",
        "* Previous prediction results: {y_pred_ma}; dataframe: {df}\n",
        "* Historical market trends indicated by the provided dataset.\n",
        "* The accuracy of the predictive model (shown in the preceding output).\n",
        "* Risk tolerance (assume moderate risk tolerance).\n",
        "* Potential diversification strategies.  Consider different asset classes (stocks, bonds, real estate, etc.) and how they might perform during predicted anomalies.\n",
        "* Actions to take during predicted anomalies (buy, sell, hold).  Provide specific details and rationales for each action.  What constitutes a \"buy\" signal? What's a \"sell\" signal?\n",
        "\n",
        "Provide a detailed investment strategy, specifying when to buy, sell, or hold assets based on the model's predictions.  The strategy should adapt based on the model's performance in previous periods. For example, if the model has been consistently inaccurate, the strategy should reduce reliance on the predictions and incorporate other indicators.  If the model has been accurate, the strategy should leverage those predictions more aggressively.  Clearly articulate how the strategy changes based on the model's predictive accuracy.  Justify each decision.\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o\",\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a financial expert providing investment advice.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"\\nInvestment Strategy Recommendation:\")\n",
        "response.choices[0].message.content"
      ],
      "metadata": {
        "id": "r7GodiMkjQic",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "outputId": "5e912c58-0880-45f6-895e-26e8d58df3ba"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.59.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "\n",
            "Investment Strategy Recommendation:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"To develop a data-driven investment strategy that minimizes losses and maximizes returns, we will consider the model's anomaly predictions, historical market trends, and a moderate risk tolerance. The goal is to use the model's predictions to optimize asset allocation and trading decisions.\\n\\n### Strategy Overview\\n\\n1. **Model Accuracy Assessment:**\\n   - Evaluate the model's predictive accuracy over historical data. If the model consistently predicts anomalies accurately (e.g., high precision and recall), weight the predictions more heavily in decision-making. If accuracy is lacking, use predictions with caution and incorporate other market indicators.\\n\\n2. **Asset Classes Consideration:**\\n   - Diversify across asset classes: equities (stocks), fixed income (bonds), commodities (like gold), currencies, and real estate.\\n   - Leverage non-correlated asset classes to hedge against market downturns during predicted anomalies.\\n\\n3. **Risk Mitigation through Diversification:**\\n   - Adopt a 60/40 allocation between equities and fixed income when no anomalies are predicted, adjusting based on market conditions.\\n   - Include a portion in commodities such as gold (XAU) as a hedge against market instability and currency risk.\\n\\n4. **Predicted Anomalies Response:**\\n   - **Buy Signals:** During market downturns (predicted anomalies) with stable indicators (e.g., low VIX), consider buying undervalued equities or ETFs, especially if historical data shows rapid recovery post-anomaly.\\n   - **Sell Signals:** If the model predicts an anomaly accompanied by market instability signals (e.g., high VIX, increasing yields), consider selling riskier assets and reallocating to safer assets like government bonds or gold.\\n   - **Hold Signals:** In periods without anomalies or mixed signals, maintain current allocations unless external macroeconomic indicators suggest otherwise. Hold positions particularly if diversification reduces overall portfolio risk.\\n\\n### Detailed Strategy Based on Model Performance\\n\\n- **When Model is Accurate:**\\n  - Use predictions to enter positions ahead of anomalies. For predicted anomalies, increase allocation in safe-haven assets (e.g., gold) and high-grade bonds (e.g., LF94TRUU_MA30) while reducing exposure to high-volatility assets like emerging market equities or currencies (e.g., MXBR_MA30, MXRU_MA30).\\n  - Consider inverse ETFs or options as hedging instruments if model predicts a market downturn.\\n\\n- **When Model Performance is Inconsistent:**\\n  - Reduce reliance on predictions and use additional indicators such as moving averages, momentum indicators (BDIY as a proxy for global trade), and macroeconomic data (e.g., consumer sentiment).\\n  - Adopt a more conservative allocation, increasing bond exposure to mitigate risks. Maintain higher cash reserves to capitalize on emerging opportunities post-anomaly.\\n\\n### Strategy Adjustment Process\\n\\n- **Continuous Monitoring:**\\n  - Review model predictions and historical performance frequently.\\n  - Adjust strategy based on upcoming economic events, policy changes, and sector-specific developments.\\n\\n- **Dynamic Rebalancing:**\\n  - Regularly rebalance portfolio to align with risk tolerance and strategic goals. During high volatility, increase frequency to ensure portfolio remains aligned with risk preferences.\\n\\n- **Incorporating Other Indicators:**\\n  - Use trend indicators like moving averages (MXUS_MA30, MXJP_MA30) to confirm predictions.\\n  - Monitor currency fluctuations (DXY, JPY, GBP) for signs of instability, influencing allocation changes in international assets.\\n\\n### Actions Summary\\n\\n- **Buy:** Predicted anomalies with stable economic signals; purchase undervalued securities.\\n- **Sell:** Predictions accompanied by instability signals; shift to more stable assets.\\n- **Hold:** Periods of no anomaly predictions or mixed signals; maintain current allocations.\\n\\n### Conclusion\\n\\nThe proposed strategy leverages the predictive model while incorporating diversification, risk management principles, and adaptive strategies based on model performance. The approach prioritizes flexibility, allowing investments to react to both predictions and external market conditions.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}